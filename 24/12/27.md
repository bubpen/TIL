# 24/12/27
## 머신러닝

#### 1. 데이터 전처리
##### - SimpleImputer
  - 결측치를 처리할 때 사용했으며, 결측치를 어떻게 처리할지 선택하여 사용한다
    ```python
    imputer1 = SimpleImputer(strategy = 'median')
    imputer2 = SimpleImputer(strategy = 'most_frequent')
    # 결측치를 다른 값으로 대체
    for i in df_median.columns:
        if df_median[i].isnull().sum() > 0:
            # CHAS 는 0 과 1로 구분되어 0으로 대체
            if i == 'CHAS':
                df_median[i] = df_median[i].fillna(0)
            else:
                df_median[i] = imputer1.fit_transform(df_median[[i]])
    ```
    괄호 안에 strategy를 mean, median, most_frequent, constant 중 하나로 설정할 수 있고, 각각 평균, 중앙값, 최빈값, 상수값으로 대체하는 imputer를 생성한다.

#### 2. 데이터 이상치 처리 시 주의 사항
  - 이상치를 처리할 때, 데이터에서 테스트 데이터와 훈련 데이터를 나누어 훈련 데이터의 이상치를 처리하고 테스트 데이터에는 그대로 두어야 한다. 그렇게 해야 테스트 데이터로 검증할 때 보다 정확한 성능을 확인할 수 있다.

#### 3. 데이터 컬럼별로 상관관계 확인
  ```python
  # 종속변수에 대한 각 컬럼의 상관관계 확인
  corr_matrix = df_median.corr()
  target_corr = corr_matrix['MEDV'].sort_values(ascending=False)
  print(target_corr)
  ```
  - pandas의 메소드인 corr()를 사용하는 것으로, 이 결과로 각 컬럼이 종속변수와 얼마의 상관관계를 가지는지 확인할 수 있다.
  - 상관관계가 높은 컬럼은 모델에 포함시키고, 낮은 컬럼은 제거하는 것이 좋다. 이는 절대값을 기준으로 한다.

#### 4. GridSearchCV
  - 모델에 사용되는 파라미터를 찾는 법으로 여러 파라미터를 사용해 그 중 가장 최적의 값을 갖는 파라미터를 찾는 하이퍼파라미터 튜닝 방법 중 하나이다.
    ```python
    from sklearn.model_selection import GridSearchCV
    # GradientBoosting 모델 하이퍼파라미터 튜닝
    gb_params = {
        'n_estimators': [50, 100, 150],
        'learning_rate': [0.01, 0.1, 0.3],
        'max_depth': [2, 3, 4],
        'random_state': [34, 42, 50]
              }

    gb = GradientBoostingRegressor()
    grid_gb = GridSearchCV(
        gb, 
        gb_params, 
        cv=5, 
        scoring='r2'
    )
    grid_gb.fit(X_train_scaled, y_train)

    print("Best GradientBoosting parameters:", grid_gb.best_params_)
    print("Best score:", grid_gb.best_score_)

    ```
    - 이는 GradientBoostingRegressor 모델에 최적의 파라미터를 찾는 코드로, gb_params에 있는 파라미터들을 사용해 최적의 파라미터를 찾는다.
    - 이 때, 평가 방법은 r2 스코어를 사용한다.

#### 5. 오늘의 회고
  - 오늘은 저번 주에 받은 과제들을 끝마치려고 하여, 전까지 한 머신러닝의 지도학습 모델을 더 알아보고 새로운 방식으로 결측치를 대체하며, 새로운 모델을 학습시켜 결과를 확인했다.
    - 해 본 결과, 앙상블 모델을 사용하며, 파라미터를 설정하여 각 성능이 달라지는 것을 확인할 수 있었으며, 각각의 모델에 대한 것과 파라미터를 정하는 방법에 유의사항도 함께 알 수 있었다.
    - 데이터에 따라 전문 지식이 있다면 파라미터의 제한을 생각하여 모델을 설정할 수 있기에, 그에 따른 지식도 함께 알아보는 것이 전처리와 모델을 학습시키는 것에 큰 도움이 될 것이라고 생각했다.
  - 비지도학습 모델들에 대한 과제도 주말에 시간을 들여 끝마치고 장고에 대한 기초 강의를 수강하면서 실습할 시간을 확보하려고 한다.
  - 오늘 하루는 머신러닝 과제에 대해 많은 시간을 들이며, 다른 사람들과의 방식을 비교하면서 더 좋은 방식도 볼 수 있었고, 좀 더 노력을 할 수 있었음을 알게 되어 곧 다가오는 새해에는 이런 후회가 없었음 하는 바램이다.