# 25/02/17 TIL
## streaming
  chat GPT를 사용해보면 타이핑을 치듯이 답을 적어주지만, 우리가 llm을 사용하면 한참을 기다리다가 한 번에 전체가 출력이 되는 것을 볼 수 있다. 이는 LLM이 실제로 한 글자 씩 생성을 하기 때문에 오래걸리는 것이고, chat GPT는 이를 하나하나 보여주는 것이다.
  이 때, streaming을 사용하는 것으로 우리도 streaming을 사용하게 되면 한 글자 씩 출력할 수 있다.
  ```python
  from langchain_openai import ChatOpenAI

  chat = ChatOpenAI(model_name="gpt-4o-mini")

  #chat.invoke("고양이에 대한 시를 써줘.") # 평소에 완성된 대답을 받던 함수 (invoke)

  for chunk in chat.stream("고양이에 대한 시를 써줘.") :
    print(chunk.content, end="", flush=True)
  ```
  invoke()를 사용하게 되면 한 번에 출력이 되게 하고, stream을 사용하면 stream() 함수를 활용하면 모델의 답변 청크를 연속적으로 받아오고 한 문자 씩 출력하는 것을 볼 수 있게 된다.

## multi-turn 대화
  chatGPT를 사용하면 연속적인 대화를 계속 기억해 대화를 이어나가는 것을 볼 수 있다. 이렇게 대화를 주고받는 것을 멀티턴(multi-turn)이라고 한다. 반대로 직전의 질문에만 답하는 것을 싱글턴(single-turn)이라고 한다.

## 오늘의 회고
  - 이제 챗봇의 기능을 어느 정도 진행을 해서 프롬프트만 다듬으면 좋은 대답을 기대할 수 있을 것 같다.
  - 전에 진행했던 LLM 특강 6번째 강의를 오늘에서야 다 들었다.
  - 이전에는 알아야 할 내용들을 전부 떠먹여준 거라는 생각이 들고, 정말 공부를 하다 보면서 새로운 이론과 개념, 그리고 이들을 사용한 라이브러리들이 많이 등장하여 따로 공부를 진행해야겠다. 따로 정리본이 있었으면 좋겠다는 생각이다.